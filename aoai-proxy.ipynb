{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure Open AI Proxy\n",
    "\n",
    "In complex, distributed scenarios, we may have the need to multiplex between multiple Open AI clients and multiple Azure Open AI deployments. In addition, it would be good to be able to track and attribute the cost of the requests per user and/or endpoint.\n",
    "\n",
    "This does exactly that, by creating a simple proxy HTTP server that sits between the client the Azure Open AI endpoint, dispatches the request to one of several endpoints, and tracks the usage and cost after each request.\n",
    "\n",
    "..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by installing FastAPI and Uvicorn (for the HTTP server), and OpenAI and Requests for making requsts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install fastapi uvicorn openai requests\n",
    "from IPython.display import clear_output ; clear_output()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our config file, we have 4 users, each with their own API key (note that this isn't a valid key for an actual Azure Open AI endpoint but rather one that we are maintaining ourselves for each users), a list of Azure Open AI endpoints, and finally, the costs per token, so that we can calculate the cost for each user and endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m# These are our application's users. Each of them has their own API key.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0mUSERS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m'Angela'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'api_key'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'angela-12345'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m'Benjamin'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'api_key'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'benjamin-23456'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m'Cynthia'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'api_key'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'cynthia-34567'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m'David'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'api_key'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'david-45678'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;31m# These are the Azure OpenAI endpoints we're proxying to.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0mAOAI_ENDPOINTS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'base_url'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' ... '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Replace with an Azure OpenAI endpoint URL.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'api_key'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' ... '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Replace with an Azure OpenAI API key.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'base_url'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' ... '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Replace with an Azure OpenAI endpoint URL.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'api_key'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' ... '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Replace with an Azure OpenAI API key.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;31m# These are the costs of each token, in USD.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;31m# Note that these costs change over time and from model to model.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0mCOMPLETION_TOKEN_COST\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.002\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0mPROMPT_TOKEN_COST\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.002\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pycat aoai_proxy_config.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our proxy server imports the config, and adds slots for tracking usage and cost per user and endpoint. It defines two REST endpoints. One is identical to the Open AI API chat completion endpoint, so that we can call it in exactly the same way we would if it were a direct call to an Azure Open AI API endpoint. It authenticartes our user based on their API key, makes a request to one of our Azure Open AI endpoints (which it returns as is to the caller) and records the use tokens as returned from the API. The other endpoint reports the usage and cost per user, endpoint and total.\n",
    "\n",
    "...\n",
    "\n",
    "Let's take a look ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32mfrom\u001b[0m \u001b[0mfastapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFastAPI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mimport\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mfrom\u001b[0m \u001b[0maoai_proxy_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUSERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAOAI_ENDPOINTS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCOMPLETION_TOKEN_COST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPROMPT_TOKEN_COST\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;31m# For each user and enpoint we'll keep track of how many tokens they've used.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mUSERS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0muser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usage'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'total_completion_tokens'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'total_prompt_tokens'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mfor\u001b[0m \u001b[0mendpoint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mAOAI_ENDPOINTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mendpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usage'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'total_completion_tokens'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'total_prompt_tokens'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;31m# Configure the OpenAI Python client to use Azure endpoints.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'azure'\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2023-03-15-preview'\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0mapp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastAPI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/openai/deployments/gpt-35-turbo/chat/completions\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mchat_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Open AI proxy endpoint for chat completions.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    This endpoint has exactly the same signature as the OpenAI API endpoint.\u001b[0m\n",
      "\u001b[0;34m    We use it to authenticate the user, choose an endpoint, and track usage.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# \"Authenticate\" the user by finding it based on the API key.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0muser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mUSERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0muser\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mUSERS\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mUSERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'api_key'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'api-key'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Choose an endpoint at random out of the list of available Azure OpenAI endpoints.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mendpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAOAI_ENDPOINTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'api_key'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'base_url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Get the body of the request, which we'll pass on to the OpenAI API.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrequest_body\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcompletion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChatCompletion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdeployment_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gpt-35-turbo'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_body\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'messages'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Track usage. Take the usage reported in the response and add it to the user and endpoint.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcompletion_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompletion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usage'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'completion_tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mprompt_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompletion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usage'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prompt_tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0muser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usage'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_completion_tokens'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcompletion_tokens\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0muser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usage'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_prompt_tokens'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mprompt_tokens\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mendpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usage'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_completion_tokens'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcompletion_tokens\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mendpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usage'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_prompt_tokens'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mprompt_tokens\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Return the response from the OpenAI API.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mcompletion\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/usage\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Get usage statistics.\u001b[0m\n",
      "\u001b[0;34m    \u001b[0m\n",
      "\u001b[0;34m    Returns a JSON object with usage and cost for each user and endpoint\u001b[0m\n",
      "\u001b[0;34m    and the total cost for all users and endpoints.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0musers_usage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mUSERS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0musers_usage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m'total_completion_tokens'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usage'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_completion_tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m'total_prompt_tokens'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usage'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_prompt_tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m'total_cost'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usage'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_completion_tokens'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mCOMPLETION_TOKEN_COST\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usage'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_prompt_tokens'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mPROMPT_TOKEN_COST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mendpoints_usage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAOAI_ENDPOINTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mendpoints_usage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'endpoint {i + 1}'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m'total_completion_tokens'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usage'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_completion_tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m'total_prompt_tokens'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usage'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_prompt_tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m'total_cost'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usage'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_completion_tokens'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mCOMPLETION_TOKEN_COST\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usage'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_prompt_tokens'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mPROMPT_TOKEN_COST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtotal_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0musers_usage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_cost'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muser\u001b[0m \u001b[0;32min\u001b[0m \u001b[0musers_usage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'users'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0musers_usage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'endpoints'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mendpoints_usage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m'total_cost'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtotal_cost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pycat aoai_proxy_server.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll run the server in the background, so that we can make requests to it (on localhost, port 8000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [9863]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from time import sleep\n",
    "\n",
    "os.system(\"\"\"uvicorn aoai_proxy_server:app &\"\"\")\n",
    "sleep(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test our proxy server, we deine a `chat` funtion, that makes a chat completion request from one of our users (using their API key), prints out the response, then calls the proxy server's usage endpoint and displays the current usage stats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import requests\n",
    "\n",
    "from aoai_proxy_config import USERS\n",
    "\n",
    "openai.api_type = 'azure'\n",
    "openai.api_version = '2023-03-15-preview'\n",
    "openai.api_base = 'http://127.0.0.1:8000'\n",
    "\n",
    "deployment_id = 'gpt-35-turbo' # Replace if using a different deployment name\n",
    "\n",
    "def chat(user, prompt):\n",
    "    openai.api_key = USERS[user]['api_key']\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        deployment_id='gpt-35-turbo',\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "    )\n",
    "    print(f'{user}: {prompt}')\n",
    "    print(completion.choices[0]['message']['content'])\n",
    "    print('---------------')\n",
    "    usage = requests.get('http://127.0.0.1:8000/usage').json()\n",
    "    print(f'Total cost: ${usage[\"total_cost\"]:.7f}')\n",
    "    for user, user_usage in usage['users'].items():\n",
    "        print(f'{user} cost: ${user_usage[\"total_cost\"]:.7f}')\n",
    "    for endpoint, endpoint_usage in usage['endpoints'].items():\n",
    "        print(f'{endpoint} cost: ${endpoint_usage[\"total_cost\"]:.7f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make some requests and see how it behaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:51042 - \"POST /openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-03-15-preview HTTP/1.1\" 200 OK\n",
      "Angela: What is the capital of France?\n",
      "The capital of France is Paris.\n",
      "---------------\n",
      "INFO:     127.0.0.1:51044 - \"GET /usage HTTP/1.1\" 200 OK\n",
      "Total cost: $0.0000440\n",
      "Angela cost: $0.0000440\n",
      "Benjamin cost: $0.0000000\n",
      "Cynthia cost: $0.0000000\n",
      "David cost: $0.0000000\n",
      "endpoint 1 cost: $0.0000000\n",
      "endpoint 2 cost: $0.0000440\n"
     ]
    }
   ],
   "source": [
    "chat('Angela', 'What is the capital of France?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:51042 - \"POST /openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-03-15-preview HTTP/1.1\" 200 OK\n",
      "Benjamin: Write a haiku about rainbows.\n",
      "Rainbow in the sky,\n",
      "Colors blend in harmony,\n",
      "Nature's gift of light.\n",
      "---------------\n",
      "INFO:     127.0.0.1:51045 - \"GET /usage HTTP/1.1\" 200 OK\n",
      "Total cost: $0.0001100\n",
      "Angela cost: $0.0000440\n",
      "Benjamin cost: $0.0000660\n",
      "Cynthia cost: $0.0000000\n",
      "David cost: $0.0000000\n",
      "endpoint 1 cost: $0.0000000\n",
      "endpoint 2 cost: $0.0001100\n"
     ]
    }
   ],
   "source": [
    "chat('Benjamin', 'Write a haiku about rainbows.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:51042 - \"POST /openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-03-15-preview HTTP/1.1\" 200 OK\n",
      "Cynthia: Count from 1 to 23.\n",
      "1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23.\n",
      "---------------\n",
      "INFO:     127.0.0.1:51046 - \"GET /usage HTTP/1.1\" 200 OK\n",
      "Total cost: $0.0002780\n",
      "Angela cost: $0.0000440\n",
      "Benjamin cost: $0.0000660\n",
      "Cynthia cost: $0.0001680\n",
      "David cost: $0.0000000\n",
      "endpoint 1 cost: $0.0000000\n",
      "endpoint 2 cost: $0.0002780\n"
     ]
    }
   ],
   "source": [
    "chat('Cynthia', 'Count from 1 to 23.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:51042 - \"POST /openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-03-15-preview HTTP/1.1\" 200 OK\n",
      "David: What are 7 words starting with the letter \"a\"?\n",
      "Apple, airplane, animal, avocado, artichoke, ambulance, astronaut.\n",
      "---------------\n",
      "INFO:     127.0.0.1:51047 - \"GET /usage HTTP/1.1\" 200 OK\n",
      "Total cost: $0.0003500\n",
      "Angela cost: $0.0000440\n",
      "Benjamin cost: $0.0000660\n",
      "Cynthia cost: $0.0001680\n",
      "David cost: $0.0000720\n",
      "endpoint 1 cost: $0.0000000\n",
      "endpoint 2 cost: $0.0003500\n"
     ]
    }
   ],
   "source": [
    "chat('David', 'What are 7 words starting with the letter \"a\"?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:51042 - \"POST /openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-03-15-preview HTTP/1.1\" 200 OK\n",
      "Angela: Who was the 11th president of the US?\n",
      "James K. Polk.\n",
      "---------------\n",
      "INFO:     127.0.0.1:51049 - \"GET /usage HTTP/1.1\" 200 OK\n",
      "Total cost: $0.0004000\n",
      "Angela cost: $0.0000940\n",
      "Benjamin cost: $0.0000660\n",
      "Cynthia cost: $0.0001680\n",
      "David cost: $0.0000720\n",
      "endpoint 1 cost: $0.0000500\n",
      "endpoint 2 cost: $0.0003500\n"
     ]
    }
   ],
   "source": [
    "chat('Angela', 'Who was the 11th president of the US?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:51042 - \"POST /openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-03-15-preview HTTP/1.1\" 200 OK\n",
      "Cynthia: What number comes after 17?\n",
      "18.\n",
      "---------------\n",
      "INFO:     127.0.0.1:51051 - \"GET /usage HTTP/1.1\" 200 OK\n",
      "Total cost: $0.0004340\n",
      "Angela cost: $0.0000940\n",
      "Benjamin cost: $0.0000660\n",
      "Cynthia cost: $0.0002020\n",
      "David cost: $0.0000720\n",
      "endpoint 1 cost: $0.0000500\n",
      "endpoint 2 cost: $0.0003840\n"
     ]
    }
   ],
   "source": [
    "chat('Cynthia', 'What number comes after 17?')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the proxy server correctly authenticates the user and makes a request on their behalf, dispatches the chat completion request to one of our available Azure Open AI endpoints, and keeps track of the costs per user and endpoint.\n",
    "\n",
    "...\n",
    "\n",
    "Before we go, we'll clean up by killing the proxy server that is running in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [9863]\n"
     ]
    }
   ],
   "source": [
    "os.system(\"\"\"kill $(ps aux | grep '[u]vicorn' | awk '{print $2}')\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
